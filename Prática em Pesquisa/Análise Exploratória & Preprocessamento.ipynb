{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis & Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th><th scope=col>Species</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>5.1   </td><td>3.5   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.9   </td><td>3.0   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.7   </td><td>3.2   </td><td>1.3   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.6   </td><td>3.1   </td><td>1.5   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>5.0   </td><td>3.6   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>5.4   </td><td>3.9   </td><td>1.7   </td><td>0.4   </td><td>setosa</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species\\\\\n",
       "\\hline\n",
       "\t 5.1    & 3.5    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 4.9    & 3.0    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 4.7    & 3.2    & 1.3    & 0.2    & setosa\\\\\n",
       "\t 4.6    & 3.1    & 1.5    & 0.2    & setosa\\\\\n",
       "\t 5.0    & 3.6    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 5.4    & 3.9    & 1.7    & 0.4    & setosa\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species |\n",
       "|---|---|---|---|---|\n",
       "| 5.1    | 3.5    | 1.4    | 0.2    | setosa |\n",
       "| 4.9    | 3.0    | 1.4    | 0.2    | setosa |\n",
       "| 4.7    | 3.2    | 1.3    | 0.2    | setosa |\n",
       "| 4.6    | 3.1    | 1.5    | 0.2    | setosa |\n",
       "| 5.0    | 3.6    | 1.4    | 0.2    | setosa |\n",
       "| 5.4    | 3.9    | 1.7    | 0.4    | setosa |\n",
       "\n"
      ],
      "text/plain": [
       "  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n",
       "1 5.1          3.5         1.4          0.2         setosa \n",
       "2 4.9          3.0         1.4          0.2         setosa \n",
       "3 4.7          3.2         1.3          0.2         setosa \n",
       "4 4.6          3.1         1.5          0.2         setosa \n",
       "5 5.0          3.6         1.4          0.2         setosa \n",
       "6 5.4          3.9         1.7          0.4         setosa "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivation:\n",
    "\n",
    "* To better understand the data. \n",
    "\n",
    "* To identify the data centrality and dispersion characteristics (median, max, min, quantiles, outliers, variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive measures:\n",
    "\n",
    "* Centrality: mean, median, mode\n",
    "\n",
    "* Dispersion: variance, standard deviation, quartiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and median: measures used to identify the asymmetry of the series.\n",
    "\n",
    "* $median < mean$: positive skewness\n",
    "\n",
    "* $median > mean$: negative skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n",
       " Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n",
       " 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n",
       " Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n",
       " Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n",
       " 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n",
       " Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n",
       "       Species  \n",
       " setosa    :50  \n",
       " versicolor:50  \n",
       " virginica :50  \n",
       "                \n",
       "                \n",
       "                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra forma de visualizar o resumo estatístico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in install.packages(\"https://cran.r-project.org/src/contrib/Archive/rlang/rlang_0.4.4.tar.gz\", :\n",
      "\"installation of package 'C:/Users/Gea/AppData/Local/Temp/RtmpkzGfGJ/downloaded_packages/rlang_0.4.4.tar.gz' had non-zero exit status\""
     ]
    }
   ],
   "source": [
    "install.packages(\"https://cran.r-project.org/src/contrib/Archive/rlang/rlang_0.4.4.tar.gz\", repo=NULL, type=\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'Hmisc' was built under R version 3.6.3\"Loading required package: ggplot2\n",
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.6.3\"Error: package or namespace load failed for 'ggplot2' in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\n",
      " there is no package called 'rlang'\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: package 'ggplot2' could not be loaded\n",
     "output_type": "error",
     "traceback": [
      "Error: package 'ggplot2' could not be loaded\nTraceback:\n",
      "1. library(Hmisc)",
      "2. .getRequiredPackages2(pkgInfo, quietly = quietly)",
      "3. stop(gettextf(\"package %s could not be loaded\", sQuote(pkg)), \n .     call. = FALSE, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(Hmisc)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(iris)\n",
    "\n",
    "# missing => missing values\n",
    "# distinct => distinct values\n",
    "# .05, .10, .25, .75, .90, .95 => percentiles\n",
    "# .50 => median\n",
    "# Gmd => Gini’s difference (measure of dispersion that is the mean absolute difference between any pairs of observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visualization:\n",
    "\n",
    "* Provide insight into an information space.\n",
    "\n",
    "* Provide a qualitative overview of large data sets.\n",
    "\n",
    "* Search for patterns, trends, structure, irregularities, relationships among data.\n",
    "\n",
    "* Help find interesting regions and suitable parameters for further quantitative analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Histogram analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogram:** display values of tabulated frequencies. It shows what proportion of cases into each category.\n",
    "\n",
    "Histograms may tell more than Boxplots.Two variables can have similar boxplots and have different data distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "library(gridExtra)\n",
    "library(ggplot2)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histA1 <- ggplot(iris, aes(x = Sepal.Length)) + geom_histogram(bins=20)\n",
    "\n",
    "histB1 <- ggplot(iris, aes(x = Sepal.Width)) + geom_histogram(bins=20)\n",
    "\n",
    "histC1 <- ggplot(iris, aes(x = Petal.Length)) + geom_histogram(bins=20)\n",
    "\n",
    "histD1 <- ggplot(iris, aes(x = Petal.Width)) + geom_histogram(bins=20)\n",
    "\n",
    "grid.arrange(histA1, histB1, histC1, histD1, ncol=2, nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histA2 <- ggplot(iris, aes(x = Sepal.Length)) + geom_histogram(bins=20) + facet_grid(~ Species)\n",
    "\n",
    "histB2 <- ggplot(iris, aes(x = Sepal.Width)) + geom_histogram(bins=20) + facet_grid(~ Species)\n",
    "\n",
    "histC2 <- ggplot(iris, aes(x = Petal.Length)) + geom_histogram(bins=20) + facet_grid(~ Species)\n",
    "\n",
    "histD2 <- ggplot(iris, aes(x = Petal.Width)) + geom_histogram(bins=20) + facet_grid(~ Species)\n",
    "\n",
    "grid.arrange(histA2, histB2, histC2, histD2, ncol=2, nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Box-plot analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boxplot:** shows the data dispersion (Q1, Q2, Q3) and possible outliers. The size of the bars is indicative of the data distortion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplotA1 <- ggplot(iris, aes(y = Sepal.Length)) + geom_boxplot()\n",
    "\n",
    "boxplotB1 <- ggplot(iris, aes(y = Sepal.Width)) + geom_boxplot()\n",
    "\n",
    "boxplotC1 <- ggplot(iris, aes(y = Petal.Length)) + geom_boxplot()\n",
    "\n",
    "boxplotD1 <- ggplot(iris, aes(y = Petal.Width)) + geom_boxplot()\n",
    "\n",
    "grid.arrange(boxplotA1, boxplotB1, boxplotC1, boxplotD1, ncol=2, nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplotA2 <- ggplot(iris, aes(x = Species, y = Sepal.Length)) + geom_boxplot()\n",
    "\n",
    "boxplotB2 <- ggplot(iris, aes(x = Species, y = Sepal.Width)) + geom_boxplot()\n",
    "\n",
    "boxplotC2 <- ggplot(iris, aes(x = Species, y = Petal.Length)) + geom_boxplot()\n",
    "\n",
    "boxplotD2 <- ggplot(iris, aes(x = Species, y = Petal.Width)) + geom_boxplot()\n",
    "\n",
    "grid.arrange(boxplotA2, boxplotB2, boxplotC2, boxplotD2, ncol=2, nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Density distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Density distribution:** shows the probability density function of a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denA1 <- ggplot(iris, aes(x = Sepal.Length)) + geom_density()\n",
    "\n",
    "denB1 <- ggplot(iris, aes(x = Sepal.Width)) + geom_density()\n",
    "\n",
    "denC1 <- ggplot(iris, aes(x = Petal.Length)) + geom_density()\n",
    "\n",
    "denD1 <- ggplot(iris, aes(x = Petal.Width)) + geom_density()\n",
    "\n",
    "grid.arrange(denA1, denB1, denC1, denD1, ncol=2, nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denA2 <- ggplot(iris, aes(x = Sepal.Length)) + geom_density() + facet_grid(~ Species)\n",
    "\n",
    "denB2 <- ggplot(iris, aes(x = Sepal.Width)) + geom_density() + facet_grid(~ Species)\n",
    "\n",
    "denC2 <- ggplot(iris, aes(x = Petal.Length)) + geom_density() + facet_grid(~ Species)\n",
    "\n",
    "denD2 <- ggplot(iris, aes(x = Petal.Width)) + geom_density() + facet_grid(~ Species)\n",
    "\n",
    "grid.arrange(denA2, denB2, denC2, denD2, ncol=2, nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Density + Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denhistA1 <- ggplot(iris, aes(x = Sepal.Length)) + \n",
    "             geom_histogram(binwidth = 0.2, color = \"black\", fill = \"steelblue\", aes(y = ..density..)) +\n",
    "             geom_density(stat = \"density\", alpha = I(0.2), fill = \"blue\") +\n",
    "             xlab(\"Sepal Length\") +  ylab(\"Density\")\n",
    "\n",
    "denhistB1 <- ggplot(iris, aes(x = Sepal.Width)) + \n",
    "             geom_histogram(binwidth = 0.2, color = \"black\", fill = \"steelblue\", aes(y = ..density..)) +\n",
    "             geom_density(stat = \"density\", alpha = I(0.2), fill = \"blue\") +\n",
    "             xlab(\"Sepal Width\") +  ylab(\"Density\")\n",
    "\n",
    "denhistC1 <- ggplot(iris, aes(x = Petal.Length)) + \n",
    "             geom_histogram(binwidth = 0.2, color = \"black\", fill = \"steelblue\", aes(y = ..density..)) +\n",
    "             geom_density(stat = \"density\", alpha = I(0.2), fill = \"blue\") +\n",
    "             xlab(\"Petal Length\") +  ylab(\"Density\")\n",
    "\n",
    "denhistD1 <- ggplot(iris, aes(x = Petal.Width)) + \n",
    "             geom_histogram(binwidth = 0.2, color = \"black\", fill = \"steelblue\", aes(y = ..density..)) +\n",
    "             geom_density(stat = \"density\", alpha = I(0.2), fill = \"blue\") +\n",
    "             xlab(\"Petal Width\") +  ylab(\"Density\")\n",
    "\n",
    "grid.arrange(denhistA1, denhistB1, denhistC1, denhistD1, ncol=2, nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labal analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denhistA2 <- ggplot(iris, aes(x = Sepal.Length, fill=Species)) +\n",
    "             geom_histogram(binwidth = 0.2, color = \"black\", fill = \"steelblue\", aes(y = ..density..)) +\n",
    "             geom_density(stat = \"density\", alpha = I(0.2), fill = \"blue\") +\n",
    "             xlab(\"Sepal Length\") +  ylab(\"Density\") +\n",
    "             facet_grid(~ Species)\n",
    "\n",
    "denhistB2 <- ggplot(iris, aes(x = Sepal.Width, fill=Species)) + \n",
    "             geom_histogram(binwidth = 0.2, color = \"black\", fill = \"steelblue\", aes(y = ..density..)) +\n",
    "             geom_density(stat = \"density\", alpha = I(0.2), fill = \"blue\") +\n",
    "             xlab(\"Sepal Width\") +  ylab(\"Density\") +\n",
    "             facet_grid(~ Species)\n",
    "\n",
    "denhistC2 <- ggplot(iris, aes(x = Petal.Length, fill=Species)) + \n",
    "             geom_histogram(binwidth = 0.2, color = \"black\", fill = \"steelblue\", aes(y = ..density..)) +\n",
    "             geom_density(stat = \"density\", alpha = I(0.2), fill = \"blue\") +\n",
    "             xlab(\"Petal Length\") +  ylab(\"Density\") +\n",
    "             facet_grid(~ Species)\n",
    "\n",
    "denhistD2 <- ggplot(iris, aes(x = Petal.Width, fill=Species)) + \n",
    "             geom_histogram(binwidth = 0.2, color = \"black\", fill = \"steelblue\", aes(y = ..density..)) +\n",
    "             geom_density(stat = \"density\", alpha = I(0.2), fill = \"blue\") +\n",
    "             xlab(\"Petal Width\") +  ylab(\"Density\") +\n",
    "             facet_grid(~ Species)\n",
    "\n",
    "grid.arrange(denhistA2, denhistB2, denhistC2, denhistD2, ncol=2, nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scatter plot:** provides the first look at bbivariate data to see clusters of points, outliers.\n",
    "\n",
    "Each pair of values is treated as a pair of coordinates ant plotted as points in the plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterA <- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n",
    "            geom_point(aes(colour = Species)) +\n",
    "            labs(x = \"Sepal Length\", y = \"Sepal Width\") + \n",
    "            scale_colour_brewer(palette = \"Dark2\", name = \"Species\") +\n",
    "            theme_bw()\n",
    "\n",
    "scatterB <- ggplot(iris, aes(x = Sepal.Length, y = Petal.Length)) +\n",
    "            geom_point(aes(colour = Species)) +\n",
    "            labs(x = \"Sepal Length\", y = \"Petal Length\") + \n",
    "            scale_colour_brewer(palette = \"Dark2\", name = \"Species\") +\n",
    "            theme_bw()\n",
    "\n",
    "scatterC <- ggplot(iris, aes(x = Sepal.Length, y = Petal.Width)) +\n",
    "            geom_point(aes(colour = Species)) +\n",
    "            labs(x = \"Sepal Length\", y = \"Petal Width\") + \n",
    "            scale_colour_brewer(palette = \"Dark2\", name = \"Species\") +\n",
    "            theme_bw()\n",
    "\n",
    "scatterD <- ggplot(iris, aes(x = Sepal.Width, y = Petal.Length)) +\n",
    "            geom_point(aes(colour = Species)) +\n",
    "            labs(x = \"Sepal Width\", y = \"Petal Length\") + \n",
    "            scale_colour_brewer(palette = \"Dark2\", name = \"Species\") +\n",
    "            theme_bw()\n",
    "\n",
    "scatterE <- ggplot(iris, aes(x = Sepal.Width, y = Petal.Width)) +\n",
    "            geom_point(aes(colour = Species)) +\n",
    "            labs(x = \"Sepal Width\", y = \"Petal Width\") + \n",
    "            scale_colour_brewer(palette = \"Dark2\", name = \"Species\") +\n",
    "            theme_bw()\n",
    "\n",
    "scatterF <- ggplot(iris, aes(x = Petal.Length, y = Petal.Width)) +\n",
    "            geom_point(aes(colour = Species)) +\n",
    "            labs(x = \"Petal Length\", y = \"Petal Width\") + \n",
    "            scale_colour_brewer(palette = \"Dark2\", name = \"Species\") +\n",
    "            theme_bw()\n",
    "\n",
    "grid.arrange(scatterA, scatterB, scatterC, scatterD, scatterE, scatterF, ncol=2, nrow=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Scatterplot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols <- c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\") \n",
    "\n",
    "pairs(iris[,1:4], pch = 19,  cex = 0.5, col = my_cols[iris$Species], lower.panel=NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major tasks in data preprocessing\n",
    "\n",
    "* Data cleaning: verifying that the data are in reasonable condition\n",
    "\n",
    "* Data integration\n",
    "\n",
    "* Data reduction: involve operations such as eliminating unneeded variables, transforming variables, and creating new variables. Make sure that you know what each variable means and whether it is sensible to include it in the model.\n",
    "\n",
    "* Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to generalize classifiers refers to your performance when classifying test patterns that were not used during training. Deficiencies in the ability to generalize a classifier can be attributed to the following factors: overfitting, overtraining and curse of dimensionality.\n",
    "\n",
    "* Overfitting: generalization loss problem (adaptation of the classifier to the specific peculiarities of the training set). When the number of features is large, the classifier tends to adapt to specific details of the training base, which can cause a reduction in the hit rate.\n",
    "\n",
    "* Overtraining: it occurs when the classifier is trained with a very large set of examples of patterns with little intra-class variation (in the case of statistical classifiers) or with many training iterations (in the case of neural classifiers). The consequence of this fact is that the classifier's generalization capacity is reduced, providing many flaws when it is used to classify standards that do not belong to the training set.\n",
    "\n",
    "* Curse of dimensionality: problem caused by the exponential increase in volume associated with adding extra dimensions to a mathematical space. This implies that for a sample size data, there is a maximum number of characteristics from which the classifier's performance will degrade, rather than improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Outliers removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpRule <- function(x, const=1.5, positions=FALSE) {\n",
    "    x <- x[!is.na(x)]\n",
    "    qs <- quantile(x, probs = c(0.25, 0.75))\n",
    "    iqr <- qs[2]-qs[1]\n",
    "    if (!positions) x[x < qs[1] - const*iqr | x > qs[2] + const*iqr]\n",
    "    else which(x < qs[1] - const*iqr | x > qs[2] + const*iqr)\n",
    "    return(x)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris2 <- iris[,-5]\n",
    "\n",
    "for (column in colnames(iris2)){\n",
    "    iris2[,column] <- bpRule(iris2[,column])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(iris2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(iris.out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Normalization Min-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxs <- apply(select(iris,-Species), 2, max, na.rm = TRUE)\n",
    "mns <- apply(select(iris,-Species), 2, min, na.rm = TRUE)\n",
    "iris_new1 <- cbind(scale(select(iris,-Species), center = mns, scale = mxs-mns), select(iris,Species))\n",
    "\n",
    "head(iris_new1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Normalization Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_new2 <- iris %>% mutate_each_(list(~scale(.) %>% as.vector),\n",
    "                                   vars = c(\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"))\n",
    "\n",
    "head(iris_new2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selection os a subset of variables (feature selection) is a task we carry out in data analysis. This may have several motivations, like for instance trying to remove irrelevant variables or variables that highly correlated with others. Another motivation for feature selection is simply reducing the dimensionality of the dataset.\n",
    "\n",
    "There are many methods we can use to select features.\n",
    "\n",
    "* **Filter methods:** involve looking at variables individually and asserting their value using some metric, which is then used to rank them and remove the less relevant ones (in terms of the selected metric).\n",
    "\n",
    "* **Wrap methods:** work by taking into consideration the objectives of the analysis we plan to carry out with the dataset. This means that they try to search for the subset of variables that are more adequate in terms of the criteria used to evaluate the results of the posterior modeling stages. These methods typically involve an iterative search procedure where at each step a candidate set of features is used to obtain a model, which is evaluated and the results of this evaluation are used to decide if the features are good enough or if we need to try other set.\n",
    "\n",
    "* **Unsupervised methods:** look at each feature individually and calculate its relevance using only the values of the variable\n",
    "\n",
    "* **Supervised methods:** explore the existence of a “special” variable in the dataset, the so-called target variable. These supervised methods evaluate each feature by looking at its relationship with the target variable. This may be as simple as calculating the correlation of each feature with the target, but it may also involve other metrics.\n",
    "\n",
    "**Obs.:** Wrapper methods are most of the time supervised methods because they typically use some predictive model to assert the value of a set of candidate features.\n",
    "\n",
    "**Obs.:** Because of this iterative search process, wrapper methods are typically more demanding in computation terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Principal components analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA:\n",
    "\n",
    "* Way to reduce the number of noninformative dimensions and to eliminate correlated variables. Once PCA has been applied, we select the most informative variables for the problem considered.\n",
    "\n",
    "* Statistical procedure that transforms and converts a data set into a new data set containing linearly uncorrelated variables, known as principal components. The basic idea is that the data set is transformed into a set of components where each one attempts to capture as much of the variance (information) in data as possible.\n",
    "\n",
    "* Unsupervised learning technique and it is used to reduce the dimension of the data with minimum loss of information.\n",
    "\n",
    "* Transforms the feature from original space to a new feature space to increase the separation between data.\n",
    "\n",
    "* Useful method for dimension reduction, especially when the number of variables is large.\n",
    "\n",
    "* **Valuable when we have subsets of measurements that are measured on the same scale and are highly correlated**\n",
    "\n",
    "* Provides a few variables (often as few as three) that are weighted linear combinations of the original variables, and that retain the majority of the information of the full original set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, this method searches for a set of “new” variables, each being a linear combination of the original variables. The idea is that a smaller set of these new variables could be able to “explain” most of the variability of the original data, and if that is the case we can carry out our analysis using only this subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important point to note before using PCA:\n",
    "\n",
    "* As PCA tries to find the linear combination of data and if the data in the dataset has non-linear relation then PCA will not work efficiently.\n",
    "\n",
    "* **Data should be normalized before performing PCA. PCA is sensitive to scaling of data as higher variance data will drive the principal component**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formalization:**\n",
    "\n",
    "Denote the original $p$ variables by $X_{1},X_{2},...,X_{p}$. In PCA, we are looking for a set of new variables $PCA_{1},PCA_{2},...,PCA_{p}$ que são médias ponderadas das variáveis originais (after subtracting their mean):\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "PCA_{i}=a_{i,1}(X_{1}-\\bar{X_{1}})+a_{i,2}(X_{2}-\\bar{X_{2}})+...+a_{i,p}(X_{p}-\\bar{X_{p}}), & i=1,...,p\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "where each pair of PCA's has correlation = 0. We then order the resulting PCA's by their variance, with $PCA_{1}$ having the largest variance and $PCA_{p}$ having the smallest variance.\n",
    "\n",
    "The further advantage of the PCA compared to the original data it that they are uncorrelated (correlation coefficient = 0). If we construct regression models using these principal components as predictors (independent variables), we will not encounter problems of multicolinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole magnitude (whole variance)\n",
    "pca <- prcomp(x = iris[,1:4], center = TRUE, scale. = TRUE)\n",
    "summary(pca)\n",
    "\n",
    "# Choose the principal components with highest variances\n",
    "\n",
    "# summary: gives the reallocated variance (Proportion of Variance)\n",
    "# 72.96% of the total variability for PC1 (can capture most of the variability in the data)\n",
    "# 22.85% of the total variability for PC2\n",
    "# 3.67% of the total variability for PC3\n",
    "# 0.52% of the total variability for PC4\n",
    "\n",
    "# the first two principal components alone capture 95.81% of the total variation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prcomp function provides four output.\n",
    "\n",
    "* Sdev: defines the standard deviation of projected points on PC1, PC2, PC3 and PC4. The standard deviation of projected point is in decreasing order from PC1 to PC4.\n",
    "\n",
    "* Rotation: defines the principal components axis. Here there are four principal components as there are four input features. The rotation is the rotation matrix, which gives the weights that are used to project the original points onto the two new directions.\n",
    "\n",
    "* Center: mean of input features in original feature space (without any transformation).\n",
    "\n",
    "* Scale: standard deviation of input features in original feature space (without any transformation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sdev')\n",
    "pca$sdev\n",
    "\n",
    "print('Rotation')\n",
    "pca$rotation\n",
    "\n",
    "print('Center')\n",
    "pca$center\n",
    "\n",
    "print('Scale')\n",
    "pca$scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores for the dimensions\n",
    "head(pca$x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the plots of projected points on principal components. It is very clear that projected points on PC1 clearly classify the data but the plots of projected points by lower principal components (for PC2, PC3 & PC4) is not able to classify the data as convincingly as PC1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow = c(2,2))\n",
    "plot(pca$x[,1], col = iris[,5])\n",
    "plot(pca$x[,2], col = iris[,5])\n",
    "plot(pca$x[,3], col = iris[,5])\n",
    "plot(pca$x[,4], col = iris[,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots show the dominance of PC1. The bar graph shows the proportion of variance explained by principal components. We can see that PC1 explains 72% of the variance, PC2 explains 23% of the variance and so on. The same has been shown in the plot below. Please note that PC1 and PC2 together explain around 95% of the variance and we can discard the PC3 and PC4 because their contribution towards explaining the variance is just 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulization of Data in the new reduced dimension\n",
    "pcar <- princomp(iris[,1:4])\n",
    "loadings(pcar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**loadings()** was used to check what were the found (rotated) axes, as well as the proportion of the original variance that is captured by each of them. \n",
    "\n",
    "From the analysis of the output of this function one can conclude that, in this example, if we used only the first three components (each component is a “new” feature) to describe the data, then we would only be capturing 75% of the original variance of the cases.\n",
    "\n",
    "The first part of the output produced by **loadings()** shows us that each of the new variables is a linear combination of the original features. For instance, in the above example we see that the 1st component (PCA1) is calculated as $0.361 \\times Sepal.Length + 0.857 \\times Petal.Length + 0.358 \\times Petal.Width$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the values of the new features for for the first 5 cases\n",
    "pcar$scores[1:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are happy with the proportion of variance explained by a small subset of the components (say the first 2). We could carry out the posterior modeling stages on this new (and reduced) feature space. For instance, instead of using the original Iris dataset we could use the scores of the first two components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced.iris <- data.frame(pcar$scores[,1:2], Species = iris$Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original dataset:')\n",
    "dim(iris)[2]\n",
    "\n",
    "print('Reduced dataset:')\n",
    "dim(reduced.iris)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boruta is a feature ranking and selection algorithm based on random forests algorithm.\n",
    "\n",
    "The advantage with Boruta is that it clearly decides if a variable is important or not and helps to select variables that are statistically significant. Besides, you can adjust the strictness of the algorithm by adjusting the p values that defaults to 0.01 and the maxRuns.\n",
    "\n",
    "maxRuns is the number of times the algorithm is run. The higher the maxRuns the more selective you get in picking the variables. The default value is 100.\n",
    "\n",
    "In the process of deciding if a feature is important or not, some features may be marked by Boruta as 'Tentative'. Sometimes increasing the maxRuns can help resolve the 'Tentativeness' of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(Boruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Boruta search\n",
    "boruta.output <- Boruta(Species ~., data = iris, doTrace = 0)\n",
    "names(boruta.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get significant variables including tentatives\n",
    "boruta.signif <- getSelectedAttributes(boruta.output, withTentative = TRUE)\n",
    "print(boruta.signif)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not sure about the tentative variables being selected for granted, you can choose a **TentativeRoughFix** on **boruta.output**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a tentative rough fix\n",
    "roughFixMod <- TentativeRoughFix(boruta.output)\n",
    "boruta.signif <- getSelectedAttributes(roughFixMod)\n",
    "print(boruta.signif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Importance Scores\n",
    "imps <- attStats(roughFixMod)\n",
    "imps2 = imps[imps$decision != 'Rejected', c('meanImp', 'decision')]\n",
    "head(imps2[order(-imps2$meanImp), ])  # descending sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot variable importance\n",
    "plot(boruta.output, cex.axis = .7, las = 2, xlab =\"\", main = \"Variable Importance\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in green are ‘confirmed’ and the ones in red are not. There are couple of blue bars representing **ShadowMax** and **ShadowMin**. They are not actual features, but are used by the boruta algorithm to decide if a variable is important or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Variable Importance from Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to look at feature selection is to consider variables most used by various ML algorithms the most to be important.\n",
    "\n",
    "Depending on how the machine learning algorithm learns the relationship between X’s and Y, different machine learning algorithms may possibly end up using different variables (but mostly common vars) to various degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(e1071)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable importances from Recursive Partitioning (rpart) algorithm (decision tree method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(100)\n",
    "rPartMod <- train(Species ~., data = iris, method = \"rpart\")\n",
    "rpartImp <- varImp(rPartMod)\n",
    "print(rpartImp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 3 of the 4 features was used by rpart and if you look closely, the variables used here are in the top that boruta selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(rpartImp, main='Variable Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable importances from Regularized Random Forest (RRF) algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(RRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an RRF model and compute variable importance.\n",
    "set.seed(100)\n",
    "rrfMod <- train(Species ~., data = iris, method=\"RRF\")\n",
    "rrfImp <- varImp(rrfMod, scale=F)\n",
    "rrfImp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(rrfImp, main='Variable Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive feature elimnation (rfe) offers a rigorous way to determine the important variables before you even feed them into a ML algo.\n",
    "\n",
    "It can be implemented using the rfe() from caret package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl <- rfeControl(functions = rfFuncs, method = \"repeatedcv\", repeats = 5, verbose = FALSE)\n",
    "# method='repeatedCV' means it will do a repeated k-Fold cross validation\n",
    "\n",
    "lmProfile <- rfe(x = iris[,-5], y = iris[,5], sizes = 3, rfeControl = ctrl)\n",
    "# sizes => determines the number of most important features the rfe should iterate\n",
    "# rfeControl parameter => receives the output of the rfeControl()\n",
    "\n",
    "lmProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmProfile$optVariables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform a supervised feature selection with genetic algorithms using the **gafs()**. This is quite resource expensive so consider that before choosing the number of iterations (iters) and the number of repeats in **gafsControl()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define control function\n",
    "ga_ctrl <- gafsControl(functions = rfGA,  # another option is `caretGA`.\n",
    "                        method = \"cv\",\n",
    "                        repeats = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Genetic Algorithm feature selection\n",
    "set.seed(100)\n",
    "ga_obj <- gafs(x = iris[,-5], \n",
    "               y = iris[, 5], \n",
    "               iters = 3,   # normally much higher (100+)\n",
    "               gafsControl = ga_ctrl)\n",
    "\n",
    "ga_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal variables\n",
    "ga_obj$optVariables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
